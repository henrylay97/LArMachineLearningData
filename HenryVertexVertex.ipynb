{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup notifications\n",
    "from time import time as tme\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "class Beeper:\n",
    "\n",
    "    def __init__(self, threshold, **audio_kwargs):\n",
    "        self.threshold = threshold\n",
    "        self.start_time = None    # time in sec, or None\n",
    "        self.audio = audio_kwargs\n",
    "\n",
    "    def pre_execute(self):\n",
    "        if not self.start_time:\n",
    "            self.start_time = tme()\n",
    "\n",
    "    def post_execute(self):\n",
    "        end_time = tme()\n",
    "        if self.start_time and end_time - self.start_time > self.threshold:\n",
    "            audio = Audio(**self.audio, autoplay=True)\n",
    "            display(audio)\n",
    "        self.start_time = None\n",
    "\n",
    "beeper = Beeper(5, filename='/usr/share/sounds/gnome/default/alerts/drip.ogg')\n",
    "\n",
    "ipython = get_ipython()\n",
    "ipython.events.register('pre_execute', beeper.pre_execute)\n",
    "ipython.events.register('post_execute', beeper.post_execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the relevant scripts from LArMachineLearningData\n",
    "# Nice the process so it can run with lots of cores on low priority\n",
    "import os\n",
    "os.nice(20)\n",
    "\n",
    "# Add path for LArMachineLearningData\n",
    "import sys\n",
    "pandoraMVADir = os.environ['PANDORAMVADIR']\n",
    "dataDir       = os.environ['PANDORABDTDATADIR']\n",
    "plotsDir      = os.environ['PANDORABDTPLOTSDIR']\n",
    "\n",
    "sys.path.append(pandoraMVADir + 'LArMachineLearningData/scripts')\n",
    "\n",
    "# Import pandora libraries\n",
    "from importlib import reload\n",
    "from PandoraBDT import *\n",
    "\n",
    "# Import concatenation tool\n",
    "from itertools import chain\n",
    "\n",
    "# Import relevant SKLearn libraries\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# Set global params\n",
    "testTrainFraction = 0.5\n",
    "nCores = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some analysis specific things\n",
    "trainingFile = dataDir + 'training_file_vertex_mix.txt'\n",
    "BDTName = \"VertexVertex\"\n",
    "\n",
    "allFeatureNames = ['Event_Showeryness', # 0\n",
    "                   'Event_Energy',\n",
    "                   'Event_Volume',\n",
    "                   'Event_Longitudinality',\n",
    "                   'Event_Num_Hits', \n",
    "                   'Event_Num_Clusters', # 5\n",
    "                   'Event_Num_Candidates', \n",
    "                   \n",
    "                   'Event_Area', # 7\n",
    "                   'Event_Longitudinality2D',\n",
    "                   'Event_Area_Average_Z',\n",
    "                   'Event_Longitudinality2D_Average_Z', #10\n",
    "                   'Event_Hit_Proportion',\n",
    "                   'Event_Energy_Proportion',\n",
    "                   'Event_Hit_Outlier_Proportion',\n",
    "                   'Event_Energy_Outlier_Proportion',\n",
    "                   'Event_Hit_Harsh_Proportion', # 15\n",
    "                   'Event_Energy_Harsh_Proportion',\n",
    "                   'Event_Hit_Outlier_Harsh_Proportion',\n",
    "                   'Event_Energy_Outlier_Harsh_Proportion',\n",
    "\n",
    "                   'Vertex1_Beam_Deweighting', # 19\n",
    "                   'Vertex1_Energy_Kick',  # 20\n",
    "                   'Vertex1_Global_Asymmetry', \n",
    "                   'Vertex1_Local_Asymmetry',\n",
    "                   'Vertex1_Shower_Asymmetry',\n",
    "\n",
    "                   'Vertex1_Global_Smooth_Asymmetry', # 24\n",
    "                   'Vertex1_Global_Asymmetry_AC', # 25\n",
    "                   'Vertex1_Global_Smooth_Asymmetry_AC',\n",
    "                   'Vertex1_Global_Asymmetry_MC',\n",
    "                   'Vertex1_Global_Smooth_Asymmetry_MC',\n",
    "                   'Vertex1_Local_Smooth_Asymmetry',\n",
    "                   'Vertex1_Shower_Smooth_Asymmetry', # 30\n",
    "                   'Vertex1_dEdx_Asymmetry',\n",
    "                   'Vertex1_dEdx_Smooth_Asymmetry',\n",
    "                   'Vertex1_dEdx_Asymmetry_AC',\n",
    "                   'Vertex1_dEdx_Smooth_Asymmetry_AC',\n",
    "                   'Vertex1_dEdx_Asymmetry_MC', # 35\n",
    "                   'Vertex1_dEdx_Smooth_Asymmetry_MC',\n",
    "                   'Vertex1_dEdx_Deviation',\n",
    "                   'Vertex1_dEdx_Deviation_AC',\n",
    "                   'Vertex1_dEdx_Deviation_MC',\n",
    "                   'Vertex1_Braggness', # 40\n",
    "                   'Vertex1_Braggness_AC',\n",
    "                   'Vertex1_Braggness_MC',\n",
    "                   'Vertex1_Energy',\n",
    "                   'Vertex1_Average_Energy',\n",
    "                   'Vertex1_Charge', # 45\n",
    "                   'Vertex1_Average_Charge',\n",
    "                   'Vertex1_Energy_Ratio',\n",
    "                   'Vertex1_Charge_Ratio',\n",
    "                   'Vertex1_Num_Local_Clusters',\n",
    "                   'Vertex1_Num_Local_Sliding_Fits', # 50\n",
    "                   'Vertex1_rPhi',\n",
    "\n",
    "                   'Vertex2_Beam_Deweighting', # 52\n",
    "                   'Vertex2_Energy_Kick',\n",
    "                   'Vertex2_Global_Asymmetry', \n",
    "                   'Vertex2_Local_Asymmetry', # 55\n",
    "                   'Vertex2_Shower_Asymmetry',\n",
    "\n",
    "                   'Vertex2_Global_Smooth_Asymmetry', # 57\n",
    "                   'Vertex2_Global_Asymmetry_AC',\n",
    "                   'Vertex2_Global_Smooth_Asymmetry_AC',\n",
    "                   'Vertex2_Global_Asymmetry_MC', # 60\n",
    "                   'Vertex2_Global_Smooth_Asymmetry_MC',\n",
    "                   'Vertex2_Local_Smooth_Asymmetry',\n",
    "                   'Vertex2_Shower_Smooth_Asymmetry',\n",
    "                   'Vertex2_dEdx_Asymmetry',\n",
    "                   'Vertex2_dEdx_Smooth_Asymmetry', # 65\n",
    "                   'Vertex2_dEdx_Asymmetry_AC',\n",
    "                   'Vertex2_dEdx_Smooth_Asymmetry_AC',\n",
    "                   'Vertex2_dEdx_Asymmetry_MC',\n",
    "                   'Vertex2_dEdx_Smooth_Asymmetry_MC',\n",
    "                   'Vertex2_dEdx_Deviation', # 70\n",
    "                   'Vertex2_dEdx_Deviation_AC',\n",
    "                   'Vertex2_dEdx_Deviation_MC',\n",
    "                   'Vertex2_Braggness',\n",
    "                   'Vertex2_Braggness_AC',\n",
    "                   'Vertex2_Braggness_MC', # 75\n",
    "                   'Vertex2_Energy',\n",
    "                   'Vertex2_Average_Energy',\n",
    "                   'Vertex2_Charge',\n",
    "                   'Vertex2_Average_Charge',\n",
    "                   'Vertex2_Energy_Ratio', # 80\n",
    "                   'Vertex2_Charge_Ratio',\n",
    "                   'Vertex2_Num_Local_Clusters',\n",
    "                   'Vertex2_Num_Local_Sliding_Fits',\n",
    "                   'Vertex2_rPhi' # 84\n",
    "                  ]\n",
    "\n",
    "# Set background and signal label names\n",
    "params = {\n",
    "    'labelNames': ['Incorrect Vertex','Correct Vertex'],\n",
    "    'signalDefs': [0, 1],\n",
    "    'signalCols': ['r', 'b']\n",
    "}\n",
    "\n",
    "# Create the base BDT to vary the params from and compare to\n",
    "baseBDT = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10),algorithm='SAMME', \n",
    "                             random_state=42, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "allData, nFeatures, nExamples = LoadData(trainingFile, ',')\n",
    "\n",
    "# Define version and variable usage\n",
    "\n",
    "version  = \"Original\"\n",
    "removals = {*range(7,19),*range(24,51),*range(57,84)}\n",
    "\n",
    "#version  = \"NewEventShapes\"\n",
    "#removals = {*range(2,4),*range(7,9),*range(11,19),*range(24,51),\n",
    "#            *range(57,84)}\n",
    "\n",
    "#version  = \"Smooth\"\n",
    "#removals = {*range(7,19),*range(21,24),*range(25,29),*range(31,51),\n",
    "#            *range(54,57),*range(58,62),*range(64,84)}\n",
    "\n",
    "#version  = \"New\"\n",
    "#removals = {*range(7,12),*range(13,19),*range(24,31),*range(32,37),\n",
    "#            *range(38,44),*range(45,49),*range(50,51),*range(57,64),\n",
    "#            *range(65,70),*range(71,77),*range(78,82),*range(83,84)}\n",
    "\n",
    "\n",
    "#version  = \"FirstPass\"\n",
    "#removals = {*range(2,4),*range(7,9),*range(15,19),*range(21,28),\n",
    "#            *range(31,36),*range(37,39),*range(40,42),*range(43,44),\n",
    "#            *range(45,49),*range(54,61),*range(64,69),*range(70,72),\n",
    "#            *range(73,75),*range(76,77),*range(78,82)}\n",
    "\n",
    "#version  = \"SmoothAndNew\"\n",
    "#removals = {*range(2,4),*range(7,9),*range(15,19),*range(21,24), \n",
    "#            *range(25,29),*range(31,32),*range(33,37),*range(38,40),\n",
    "#            *range(41,44),*range(45,49),*range(54,57),*range(58,62),\n",
    "#            *range(64,65),*range(66,70),*range(71,73),*range(74,77),\n",
    "#            *range(78,82)}\n",
    "\n",
    "# Using better hyperparameters ?\n",
    "#version += \"_HighHP\"\n",
    "version += \"_ThinHP\"\n",
    "\n",
    "# Plotting Directory\n",
    "topDir = plotsDir + '/' + BDTName + '/' + version + '/'\n",
    "\n",
    "# Remove unwanted features\n",
    "data         = RemoveFeature(allData,removals)\n",
    "featureNames = []\n",
    "\n",
    "for i in [x for x in range(0,nFeatures) if x not in removals]:\n",
    "    featureNames.append(allFeatureNames[i])\n",
    "\n",
    "# Redefine size\n",
    "nFeatures = len(data[0]) - 1\n",
    "\n",
    "# Check removals\n",
    "print(nFeatures, \" =? \", len(featureNames))\n",
    "print(featureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresOrg, labelsOrg    = SplitTrainingSet(data, nFeatures)\n",
    "weightsOrg                = GetWeights(data,6)\n",
    "features, labels, weights = Randomize(featuresOrg, labelsOrg, weightsOrg, True)\n",
    "\n",
    "# Split into train and test samples\n",
    "xTrain, yTrain, weightsTrain, xTest, yTest, weightsTest = Sample(features, labels, weights, testTrainFraction)\n",
    "\n",
    "# Split into signal and background based on the true labels\n",
    "signalFeatures = features[labels==1]\n",
    "backgroundFeatures = features[labels==0]\n",
    "\n",
    "# Check the features array is the same size as the feature names array\n",
    "print (len(featureNames))\n",
    "print (np.shape(features))\n",
    "print('Total: '+str(len(features))+', signal: '+\n",
    "      str(len(signalFeatures))+' and background: '+\n",
    "      str(len(backgroundFeatures)))\n",
    "print (len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Pandas dataframe\n",
    "# First create a dictionary\n",
    "allDict = {featureNames[i]: features[:, i] for i in range(nFeatures)}\n",
    "allDict.update({'Labels': labels})\n",
    "\n",
    "# Create the Pandas dataframe, create seperate df for signal/background\n",
    "df = pd.DataFrame(data=allDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots drawing the variables for signal/background\n",
    "DrawVariablesDF(df, params, topDir, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make correlation matricies\n",
    "Correlation(df[df['Labels']==params['signalDefs'][0]], params['labelNames'][0] + ' Correlation Matrix',topDir, save = False)\n",
    "Correlation(df[df['Labels']==params['signalDefs'][1]], params['labelNames'][1] + ' Correlation Matrix',topDir, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference BDT with controlled hyperparams\n",
    "#baseBDT.fit(xTrain,yTrain, sample_weight = weightsTrain)\n",
    "baseBDT.fit(xTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots()\n",
    "metrics.plot_roc_curve(baseBDT, xTest, yTest, ax=ax)\n",
    "\n",
    "plt.title(\"ROC Curves\")\n",
    "ax.invert_xaxis()\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.savefig(topDir + '/' + \"roc.png\", bbox_inches='tight')\n",
    "plt.savefig(topDir + '/' + \"roc.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matricies\n",
    "fig, ax = plt.subplots()\n",
    "metrics.plot_confusion_matrix(baseBDT, xTest, yTest, display_labels=params['labelNames'],\n",
    "                             ax=ax, normalize='true')\n",
    "ax.invert_xaxis()\n",
    "plt.title(\"Confusion matrix (True Normalised)\")\n",
    "\n",
    "plt.savefig(topDir + '/' + \"confusion_matrix.png\", bbox_inches='tight')\n",
    "plt.savefig(topDir + '/' + \"confusion_matrix.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print more detailed performance info\n",
    "bdtPredicted = baseBDT.predict(xTest)\n",
    "\n",
    "print (\"Background (0): \", params['labelNames'][0])\n",
    "print (\"Signal (1): \", params['labelNames'][1])\n",
    "print (\"BDT:\\n\", metrics.classification_report(yTest, bdtPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot importance of features\n",
    "importanceDF = pd.DataFrame({'Features': featureNames, 'Importance Score':baseBDT.feature_importances_})\n",
    "print (importanceDF.sort_values(by=['Importance Score']))\n",
    "ax = importanceDF.sort_values(by=['Importance Score'])\\\n",
    "    .plot(kind='barh', x='Features', y='Importance Score')\n",
    "\n",
    "plt.savefig(topDir + '/' + \"feature_importance.png\", bbox_inches='tight')\n",
    "plt.savefig(topDir + '/' + \"feature_importance.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all tunable params\n",
    "baseBDT.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PandoraBDT\n",
    "reload (PandoraBDT)\n",
    "from PandoraBDT import *\n",
    "\n",
    "parameters = {\n",
    "  'ClassNames': ['True Vertex', 'Incorrect Vertex'],\n",
    "  'SignalDefinition': [1, 0],\n",
    "  'PlotColors': ['b', 'r'],\n",
    "  'nBins': 100,\n",
    "  'PlotStep': 1.0,\n",
    "  'OptimalBinCut': 0,\n",
    "  'OptimalScoreCut': 0.0,\n",
    "  'nTrees': 100,\n",
    "  'TreeDepth': 3\n",
    "}\n",
    "\n",
    "FindOptimalSignificanceCut(baseBDT, xTest, yTest, parameters)\n",
    "PlotBdtScores(baseBDT, xTest, yTest, xTrain, yTrain, 'Vertex Vertex', parameters, topDir, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseBDT.score(xTest,yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WriteXmlFile(BDTName+\".xml\", baseBDT, BDTName)\n",
    "SerializeToPkl(BDTName+\".pkl\", baseBDT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
