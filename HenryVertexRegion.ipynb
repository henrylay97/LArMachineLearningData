{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the relevant scripts from LArMachineLearningData\n",
    "# Nice the process so it can run with lots of cores on low priority\n",
    "import os\n",
    "os.nice(20)\n",
    "\n",
    "# Add path for LArMachineLearningData\n",
    "import sys\n",
    "pandoraMVADir = os.environ['PANDORAMVADIR']\n",
    "dataDir       = os.environ['PANDORABDTDATADIR']\n",
    "plotsDir      = os.environ['PANDORABDTPLOTSDIR']\n",
    "\n",
    "sys.path.append(pandoraMVADir + 'LArMachineLearningData/scripts')\n",
    "\n",
    "# Import pandora libraries\n",
    "from importlib import reload\n",
    "from PandoraBDT import *\n",
    "\n",
    "# Import concatenation tool\n",
    "from itertools import chain\n",
    "\n",
    "# Import relevant SKLearn libraries\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# Set global params\n",
    "testTrainFraction = 0.5\n",
    "nCores = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some analysis specific things\n",
    "trainingFile = dataDir + 'training_file_region_mix.txt'\n",
    "BDTName = \"VertexRegion\"\n",
    "\n",
    "allFeatureNames = ['Event_Showeryness', # 0\n",
    "                   'Event_Energy',\n",
    "                   'Event_Volume',\n",
    "                   'Event_Longitudinality',\n",
    "                   'Event_Num_Hits', \n",
    "                   'Event_Num_Clusters', # 5\n",
    "                   'Event_Num_Candidates', \n",
    "                   \n",
    "                   'Event_Area', # 7\n",
    "                   'Event_Longitudinality2D',\n",
    "                   'Event_Area_Average_Z',\n",
    "                   'Event_Longitudinality2D_Average_Z', #10\n",
    "                   'Event_Hit_Proportion',\n",
    "                   'Event_Energy_Proportion',\n",
    "                   'Event_Hit_Outlier_Proportion',\n",
    "                   'Event_Energy_Outlier_Proportion',\n",
    "                   'Event_Hit_Harsh_Proportion', # 15\n",
    "                   'Event_Energy_Harsh_Proportion',\n",
    "                   'Event_Hit_Outlier_Harsh_Proportion',\n",
    "                   'Event_Energy_Outlier_Harsh_Proportion',\n",
    "\n",
    "                   'Vertex1_Beam_Deweighting', # 19\n",
    "                   'Vertex1_Energy_Kick',  # 20\n",
    "                   'Vertex1_Global_Asymmetry', \n",
    "                   'Vertex1_Local_Asymmetry',\n",
    "                   'Vertex1_Shower_Asymmetry',\n",
    "\n",
    "                   'Vertex1_Global_Smooth_Asymmetry', # 24\n",
    "                   'Vertex1_Global_Asymmetry_AC', # 25\n",
    "                   'Vertex1_Global_Smooth_Asymmetry_AC',\n",
    "                   'Vertex1_Global_Asymmetry_MC',\n",
    "                   'Vertex1_Global_Smooth_Asymmetry_MC',\n",
    "                   'Vertex1_Local_Smooth_Asymmetry',\n",
    "                   'Vertex1_Shower_Smooth_Asymmetry', # 30\n",
    "                   'Vertex1_dEdx_Asymmetry',\n",
    "                   'Vertex1_dEdx_Smooth_Asymmetry',\n",
    "                   'Vertex1_dEdx_Asymmetry_AC',\n",
    "                   'Vertex1_dEdx_Smooth_Asymmetry_AC',\n",
    "                   'Vertex1_dEdx_Asymmetry_MC', # 35\n",
    "                   'Vertex1_dEdx_Smooth_Asymmetry_MC',\n",
    "                   'Vertex1_dEdx_Deviation',\n",
    "                   'Vertex1_dEdx_Deviation_AC',\n",
    "                   'Vertex1_dEdx_Deviation_MC',\n",
    "                   'Vertex1_Braggness', # 40\n",
    "                   'Vertex1_Braggness_AC',\n",
    "                   'Vertex1_Braggness_MC',\n",
    "                   'Vertex1_Energy',\n",
    "                   'Vertex1_Average_Energy',\n",
    "                   'Vertex1_Charge', # 45\n",
    "                   'Vertex1_Average_Charge',\n",
    "                   'Vertex1_Energy_Ratio',\n",
    "                   'Vertex1_Charge_Ratio',\n",
    "                   'Vertex1_Num_Local_Clusters',\n",
    "                   'Vertex1_Num_Local_Sliding_Fits', # 50\n",
    "\n",
    "                   'Vertex2_Beam_Deweighting', # 51\n",
    "                   'Vertex2_Energy_Kick',\n",
    "                   'Vertex2_Global_Asymmetry', \n",
    "                   'Vertex2_Local_Asymmetry',\n",
    "                   'Vertex2_Shower_Asymmetry', # 55\n",
    "\n",
    "                   'Vertex2_Global_Smooth_Asymmetry', # 56\n",
    "                   'Vertex2_Global_Asymmetry_AC',\n",
    "                   'Vertex2_Global_Smooth_Asymmetry_AC',\n",
    "                   'Vertex2_Global_Asymmetry_MC',\n",
    "                   'Vertex2_Global_Smooth_Asymmetry_MC', # 60\n",
    "                   'Vertex2_Local_Smooth_Asymmetry',\n",
    "                   'Vertex2_Shower_Smooth_Asymmetry',\n",
    "                   'Vertex2_dEdx_Asymmetry',\n",
    "                   'Vertex2_dEdx_Smooth_Asymmetry',\n",
    "                   'Vertex2_dEdx_Asymmetry_AC', # 65\n",
    "                   'Vertex2_dEdx_Smooth_Asymmetry_AC',\n",
    "                   'Vertex2_dEdx_Asymmetry_MC',\n",
    "                   'Vertex2_dEdx_Smooth_Asymmetry_MC',\n",
    "                   'Vertex2_dEdx_Deviation',\n",
    "                   'Vertex2_dEdx_Deviation_AC', # 70\n",
    "                   'Vertex2_dEdx_Deviation_MC',\n",
    "                   'Vertex2_Braggness',\n",
    "                   'Vertex2_Braggness_AC',\n",
    "                   'Vertex2_Braggness_MC',\n",
    "                   'Vertex2_Energy', # 75\n",
    "                   'Vertex2_Average_Energy',\n",
    "                   'Vertex2_Charge',\n",
    "                   'Vertex2_Average_Charge',\n",
    "                   'Vertex2_Energy_Ratio',\n",
    "                   'Vertex2_Charge_Ratio', # 80\n",
    "                   'Vertex2_Num_Local_Clusters',\n",
    "                   'Vertex2_Num_Local_Sliding_Fits' # 82\n",
    "                  ]\n",
    "\n",
    "# Set background and signal label names\n",
    "params = {\n",
    "    'labelNames': ['Incorrect Vertex','Correct Vertex'],\n",
    "    'signalDefs': [0, 1],\n",
    "    'signalCols': ['r', 'b']\n",
    "}\n",
    "\n",
    "# Create the base BDT to vary the params from and compare to\n",
    "baseBDT = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),algorithm='SAMME', \n",
    "                             random_state=42, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "allData, nFeatures, nExamples = LoadData(trainingFile, ',')\n",
    "\n",
    "# Define version and variable usage\n",
    "\n",
    "version  = \"Original\"\n",
    "removals = {*range(7,19),*range(24,51),*range(56,83)}\n",
    "\n",
    "#version  = \"2DEventShapes\"\n",
    "#removals = {*range(2,4),*range(9,19),*range(24,51),*range(56,83)}\n",
    "\n",
    "\n",
    "# Plotting Directory\n",
    "topDir = plotsDir + '/' + BDTName + '/' + version + '/'\n",
    "\n",
    "# Remove unwanted features\n",
    "data         = RemoveFeature(allData,removals)\n",
    "featureNames = []\n",
    "\n",
    "for i in [x for x in range(0,nFeatures) if x not in removals]:\n",
    "    featureNames.append(allFeatureNames[i])\n",
    "\n",
    "# Redefine size\n",
    "nFeatures = len(data[0]) - 1\n",
    "\n",
    "# Check removals\n",
    "print(nFeatures, \" =? \", len(featureNames))\n",
    "print(featureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresOrg, labelsOrg = SplitTrainingSet(data, nFeatures)\n",
    "features, labels = Randomize(featuresOrg, labelsOrg, True)\n",
    "\n",
    "# Split into train and test samples\n",
    "xTrain, yTrain, xTest, yTest = Sample(features, labels, testTrainFraction)\n",
    "\n",
    "# Split into signal and background based on the true labels\n",
    "signalFeatures = features[labels==1]\n",
    "backgroundFeatures = features[labels==0]\n",
    "\n",
    "# Check the features array is the same size as the feature names array\n",
    "print (len(featureNames))\n",
    "print (np.shape(features))\n",
    "print('Total: '+str(len(features))+', signal: '+\n",
    "      str(len(signalFeatures))+' and background: '+\n",
    "      str(len(backgroundFeatures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Pandas dataframe\n",
    "# First create a dictionary\n",
    "allDict = {featureNames[i]: features[:, i] for i in range(nFeatures)}\n",
    "allDict.update({'Labels': labels})\n",
    "\n",
    "# Create the Pandas dataframe, create seperate df for signal/background\n",
    "df = pd.DataFrame(data=allDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots drawing the variables for signal/background\n",
    "DrawVariablesDF(df, params, topDir, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make correlation matricies\n",
    "Correlation(df[df['Labels']==params['signalDefs'][0]], params['labelNames'][0] + ' Correlation Matrix',topDir, save = False)\n",
    "Correlation(df[df['Labels']==params['signalDefs'][1]], params['labelNames'][1] + ' Correlation Matrix',topDir, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference BDT with controlled hyperparams\n",
    "baseBDT.fit(xTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots()\n",
    "metrics.plot_roc_curve(baseBDT, xTest, yTest, ax=ax)\n",
    "\n",
    "plt.title(\"ROC Curves\")\n",
    "ax.invert_xaxis()\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "#plt.savefig(topDir + '/' + \"roc.png\", bbox_inches='tight')\n",
    "#plt.savefig(topDir + '/' + \"roc.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matricies\n",
    "fig, ax = plt.subplots()\n",
    "metrics.plot_confusion_matrix(baseBDT, xTest, yTest, display_labels=params['labelNames'],\n",
    "                             ax=ax, normalize='true')\n",
    "ax.invert_xaxis()\n",
    "plt.title(\"Confusion matrix (True Normalised)\")\n",
    "\n",
    "#plt.savefig(topDir + '/' + \"confusion_matrix.png\", bbox_inches='tight')\n",
    "#plt.savefig(topDir + '/' + \"confusion_matrix.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print more detailed performance info\n",
    "bdtPredicted = baseBDT.predict(xTest)\n",
    "\n",
    "print (\"Background (0): \", params['labelNames'][0])\n",
    "print (\"Signal (1): \", params['labelNames'][1])\n",
    "print (\"BDT:\\n\", metrics.classification_report(yTest, bdtPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot importance of features\n",
    "importanceDF = pd.DataFrame({'Features': featureNames, 'Importance Score':baseBDT.feature_importances_})\n",
    "print (importanceDF.sort_values(by=['Importance Score']))\n",
    "ax = importanceDF.sort_values(by=['Importance Score'])\\\n",
    "    .plot(kind='barh', x='Features', y='Importance Score')\n",
    "\n",
    "#plt.savefig(topDir + '/' + \"feature_importance.png\", bbox_inches='tight')\n",
    "#plt.savefig(topDir + '/' + \"feature_importance.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all tunable params\n",
    "baseBDT.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PandoraBDT\n",
    "reload (PandoraBDT)\n",
    "from PandoraBDT import *\n",
    "\n",
    "parameters = {\n",
    "  'ClassNames': ['True Vertex', 'Incorrect Vertex'],\n",
    "  'SignalDefinition': [1, 0],\n",
    "  'PlotColors': ['b', 'r'],\n",
    "  'nBins': 100,\n",
    "  'PlotStep': 1.0,\n",
    "  'OptimalBinCut': 0,\n",
    "  'OptimalScoreCut': 0.0,\n",
    "  'nTrees': 100,\n",
    "  'TreeDepth': 3\n",
    "}\n",
    "\n",
    "FindOptimalSignificanceCut(baseBDT, xTest, yTest, parameters)\n",
    "PlotBdtScores(baseBDT, xTest, yTest, xTrain, yTrain, 'Vertex Region', parameters, topDir, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WriteXmlFile(BDTName+\".xml\", baseBDT, BDTName)\n",
    "SerializeToPkl(BDTName+\".pkl\", baseBDT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
